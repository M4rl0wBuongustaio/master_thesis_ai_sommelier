{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The following Collaborative Filtering approach is based on <a href=\"https://pub.towardsai.net/recommendation-system-in-depth-tutorial-with-python-for-netflix-using-collaborative-filtering-533ff8a0e444\">this</a> article."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sqlite3\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import thesis_utilities, collaborative_filtering_textual\n",
    "from multiprocessing_scripts import recommender_nlp\n",
    "from scipy import sparse\n",
    "import cf_multiprocessing\n",
    "import concurrent.futures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_from_database(\n",
    "        db: str,\n",
    "        table: str,\n",
    "        columns: str,\n",
    "):\n",
    "    connection = sqlite3.connect('../database/' + db + '.db')\n",
    "    df = pd.read_sql_query(\n",
    "        str('SELECT ' + columns + ' FROM ' + table), con=connection\n",
    "    )\n",
    "    connection.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_to_database(\n",
    "        db: str,\n",
    "        table: str,\n",
    "        df: pd.DataFrame\n",
    "):\n",
    "    connection = sqlite3.connect('../database/' + db + '.db')\n",
    "    try:\n",
    "        df.to_sql(name=table, con=connection, if_exists='replace')\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    print('DataFrame has been saved successfully to: ' + db)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inser Heading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def get_mse_for_predictions(predictions: dict, test_reviews: pd.DataFrame, input_user: int):\n",
    "    y_test = test_reviews[(test_reviews.user_id == input_user)]\n",
    "    y_pred = pd.DataFrame(predictions.items(), columns=['wine_id', 'predicted_rating'])\n",
    "    joined_df = y_test.merge(y_pred, how='left', on='wine_id').dropna()\n",
    "    return mean_squared_error(y_true=joined_df.rating, y_pred=joined_df.predicted_rating)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def evaluate_collaborative_filtering(df_list: list):\n",
    "    df_test = df_list[0]\n",
    "    df_train = df_list[1]\n",
    "    input_users = df_train[df_train.user_id.isin(df_test.user_id)].user_id.unique()\n",
    "    sim_matrix = get_sim_matrix(train_rev_matrix)\n",
    "    unpredictable_users = []\n",
    "    df = pd.DataFrame(data={}.items(), columns=['wine_id', 'rating', 'rating_predicted'])\n",
    "\n",
    "    for user in input_users:\n",
    "        try:\n",
    "            sim_users = get_top_n_similar_users(n=10, sim_matrix=sim_matrix, input_user=user)\n",
    "            preds: dict = get_n_predictions(input_user=user, similar_users=sim_users, reviews=df_train,\n",
    "                                            threshold=3.0, is_evaluation=True)\n",
    "            df_temp = pd.DataFrame(preds.items(), columns=['wine_id', 'rating_predicted']).merge(\n",
    "                df_test.loc[df_test.user_id == user, ['wine_id', 'rating']], on='wine_id', how='left')\n",
    "            df = pd.concat([df, df_temp])\n",
    "        except Exception as err:\n",
    "            unpredictable_users.append(user)\n",
    "            print('No wines could be predicted for user: ' + str(user) + ' (' + str(err) + ')')\n",
    "            raise err\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_rev_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [32]\u001B[0m, in \u001B[0;36m<cell line: 19>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;28mprint\u001B[39m(mean_squared_error(y_true\u001B[38;5;241m=\u001B[39mdf_results\u001B[38;5;241m.\u001B[39mrating, y_pred\u001B[38;5;241m=\u001B[39mdf_results\u001B[38;5;241m.\u001B[39mrating_predicted))\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 20\u001B[0m     \u001B[43mrun_multiprocessing\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [32]\u001B[0m, in \u001B[0;36mrun_multiprocessing\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m df_results \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(data\u001B[38;5;241m=\u001B[39m{}\u001B[38;5;241m.\u001B[39mitems(), columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwine_id\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrating\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrating_predicted\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      3\u001B[0m core_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[0;32m----> 4\u001B[0m len_df_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[43mtrain_rev_df\u001B[49m) \u001B[38;5;241m/\u001B[39m core_count)\n\u001B[1;32m      5\u001B[0m len_df_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(test_rev_df) \u001B[38;5;241m/\u001B[39m core_count)\n\u001B[1;32m      6\u001B[0m test_frames \u001B[38;5;241m=\u001B[39m [train_rev_df\u001B[38;5;241m.\u001B[39miloc[i \u001B[38;5;241m*\u001B[39m len_df_train:(i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m len_df_train]\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(core_count \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_rev_df' is not defined"
     ]
    }
   ],
   "source": [
    "def run_multiprocessing():\n",
    "    df_results = pd.DataFrame(data={}.items(), columns=['wine_id', 'rating', 'rating_predicted'])\n",
    "    core_count = 10\n",
    "    len_df_train = int(len(train_rev_df) / core_count)\n",
    "    len_df_test = int(len(test_rev_df) / core_count)\n",
    "    test_frames = [train_rev_df.iloc[i * len_df_train:(i + 1) * len_df_train].copy() for i in range(core_count + 1)]\n",
    "    train_frames = [test_rev_df.iloc[i * len_df_test:(i + 1) * len_df_test].copy() for i in range(core_count + 1)]\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = [\n",
    "            executor.submit(cf_multiprocessing.evaluate_collaborative_filtering, [test_frames[i], train_frames[i]]) for\n",
    "            i in range(core_count)]\n",
    "\n",
    "        for result in concurrent.futures.as_completed(results):\n",
    "            df_results = pd.concat([df_results, result.result()])\n",
    "        print(df_results)\n",
    "        print(mean_squared_error(y_true=df_results.rating, y_pred=df_results.rating_predicted))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_multiprocessing()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare evaluation Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_embedder(path: str):\n",
    "    embedder = SentenceTransformer.load(path)\n",
    "    if torch.has_mps:\n",
    "        embedder.to('mps')\n",
    "    return embedder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_n_similar_user(\n",
    "        input_user_id: int,\n",
    "        review_pool: pd.DataFrame,  # containing input_user's and other user's reviews\n",
    "        embedder_path: str,\n",
    "        n: int\n",
    ") -> pd.DataFrame:\n",
    "    user_list = []\n",
    "    similarity_list = []\n",
    "    embedder: SentenceTransformer = get_embedder(embedder_path)\n",
    "    input_user_rated_wines = review_pool[review_pool['user_id'] == input_user_id]['wine_id'].unique()\n",
    "    candidates = review_pool[\n",
    "        (review_pool['user_id'] != input_user_id) &\n",
    "        (review_pool['wine_id'].isin(input_user_rated_wines))\n",
    "        ]['user_id'].unique()\n",
    "\n",
    "    input_user_notes = review_pool[review_pool['user_id'] == input_user_id]['note'].tolist()\n",
    "    input_user_embedding = embedder.encode(input_user_notes, convert_to_tensor=True)\n",
    "\n",
    "    for candidate in candidates:\n",
    "        candidate_notes: list = review_pool[review_pool['user_id'] == candidate]['note'].tolist()\n",
    "        candidate_embedding = embedder.encode(candidate_notes, convert_to_tensor=True)\n",
    "        similarity = util.cos_sim(a=input_user_embedding, b=candidate_embedding).mean()\n",
    "        user_list.append(candidate)\n",
    "        similarity_list.append(np.round(float(similarity.mean()), decimals=6))\n",
    "    similar_user = pd.DataFrame(\n",
    "        {'user_id': user_list, 'similarity': similarity_list}\n",
    "    )\n",
    "    similar_user.sort_values(by='similarity', ascending=False, inplace=True)\n",
    "    return similar_user.head(n=n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_predictions(\n",
    "        review_pool: pd.DataFrame,\n",
    "        input_user_id: int,\n",
    "        similar_user_id: int,\n",
    "        target_wines: list = None\n",
    ") -> pd.DataFrame:\n",
    "    input_user_avg_rating = np.round(review_pool[review_pool['user_id'] == input_user_id]['rating'].mean(), decimals=1)\n",
    "    predictions_list = list()\n",
    "    wines_list = list()\n",
    "    input_user_list = list()\n",
    "\n",
    "    if target_wines is None:\n",
    "        target_wines: list = review_pool[\n",
    "            (review_pool['user_id'] == similar_user_id) &\n",
    "            (review_pool['user_id'] != input_user_id)\n",
    "            ]['wine_id'].tolist()\n",
    "\n",
    "    sim_user_avg_rating = np.round(review_pool[review_pool['user_id'] == similar_user_id]['rating'].mean(), decimals=1)\n",
    "    for target_wine in target_wines:\n",
    "        sim_user_rating: float = review_pool[\n",
    "            (review_pool['user_id'] == similar_user_id) & (review_pool['wine_id'] == target_wine)]['rating'].values[\n",
    "            0]\n",
    "        prediction: float = np.round(\n",
    "            input_user_avg_rating + (sim_user_rating - sim_user_avg_rating), decimals=1)\n",
    "        predictions_list.append(prediction)\n",
    "        wines_list.append(target_wine)\n",
    "        input_user_list.append(input_user_id)\n",
    "    return pd.DataFrame({'user_id': input_user_list, 'wine_id': wines_list, 'prediction': predictions_list})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def evaluate_recommender(\n",
    "        df_train: pd.DataFrame,\n",
    "        df_test: pd.DataFrame,\n",
    "        type: str,\n",
    "        n_predictions: int,\n",
    "        model_path: str = '../models/zero-shot',\n",
    "        input_user_list=None,\n",
    "        is_evaluation: bool = None\n",
    "):\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    if input_user_list is None:\n",
    "        input_user_list = df_train['user_id']\n",
    "\n",
    "    if type == 'nlp':\n",
    "        print('Selected model path: ', model_path)\n",
    "        for input_user_id in input_user_list:\n",
    "            input_user_rated_wines: list = df_train[df_train['user_id'] == input_user_id]['wine_id'].tolist()\n",
    "            input_user_rated_wines_test: list = df_test[df_test['user_id'] == input_user_id]['wine_id'].tolist()\n",
    "            if is_evaluation:\n",
    "                # Ensure, user can be evaluated against input user.\n",
    "                review_pool: pd.DataFrame = df_train[\n",
    "                    df_train['wine_id'].isin(input_user_rated_wines)\n",
    "                ]\n",
    "                # Reduce to input-user-reviews in training data.\n",
    "                evaluation_ready_user = df_test[df_test['wine_id'].isin(input_user_rated_wines_test)]['user_id'].unique().tolist()\n",
    "                review_pool = review_pool[review_pool['user_id'].isin(evaluation_ready_user)]\n",
    "            else:\n",
    "                review_pool = df_train[\n",
    "                    df_train['wine_id'].isin(input_user_rated_wines)\n",
    "                ]\n",
    "            similar_user: pd.DataFrame = collaborative_filtering_textual.get_n_similar_user(\n",
    "                input_user_id=input_user_id, review_pool=review_pool,\n",
    "                embedder_path=model_path, n=n_predictions\n",
    "            )\n",
    "            for similar_user_id in similar_user['user_id']:\n",
    "                target_wines = list(set(df_test[df_test['user_id'] == similar_user_id]['wine_id']) &\n",
    "                                    set(input_user_rated_wines_test))\n",
    "                df_predictions = get_predictions(\n",
    "                    review_pool=pd.concat([df_train, df_test]), input_user_id=input_user_id,\n",
    "                    similar_user_id=similar_user_id, target_wines=target_wines,\n",
    "                )\n",
    "                # print('df_predictions: ', str(df_predictions))\n",
    "                df_results = pd.concat([df_results, df_predictions])\n",
    "    elif type == 'rating':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Please set a valid recommender type (nlp/rating)!')\n",
    "    df_results = df_results.merge(df_test[['user_id', 'wine_id', 'rating']], on=['user_id', 'wine_id'])\n",
    "    mse: float = mean_squared_error(y_pred=df_results['prediction'], y_true=df_results['rating'])\n",
    "    print(mse)\n",
    "    return mse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_en_train = load_from_database(db='review_en_train', table='review_en_train',\n",
    "                                 columns='user_id, wine_id, note, rating')\n",
    "df_en_test = load_from_database(db='review_en_test', table='review_en_test',\n",
    "                                columns='user_id, wine_id, note, rating')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model path:  ../models/simcse_en\n",
      "0.5405\n",
      "0:00:01.358050\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "evaluate_recommender(\n",
    "    df_train=df_en_train, df_test=df_en_test, type='nlp', n_predictions=20, model_path='../models/simcse_en',\n",
    "    input_user_list=[27493713], is_evaluation=True)\n",
    "print(datetime.datetime.now() - start)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
