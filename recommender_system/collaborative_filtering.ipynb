{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "The following Collaborative Filtering approach is based on <a href=\"https://pub.towardsai.net/recommendation-system-in-depth-tutorial-with-python-for-netflix-using-collaborative-filtering-533ff8a0e444\">this</a> article."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import recommender_system\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_from_database(\n",
    "        db: str,\n",
    "        table: str,\n",
    "        columns: str,\n",
    "):\n",
    "    connection = sqlite3.connect('../database/' + db + '.db')\n",
    "    df = pd.read_sql_query(\n",
    "        str('SELECT ' + columns + ' FROM ' + table), con=connection\n",
    "    )\n",
    "    connection.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_to_database(\n",
    "        db: str,\n",
    "        table: str,\n",
    "        df: pd.DataFrame\n",
    "):\n",
    "    connection = sqlite3.connect('../database/' + db + '.db')\n",
    "    try:\n",
    "        df.to_sql(name=table, con=connection, if_exists='replace')\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    print('DataFrame has been saved successfully to: ' + db)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inser Heading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df_en_train = load_from_database(db='review_en_sc_train', table='review_en_sc_train',\n",
    "                                 columns='user_id, wine_id, note, rating, likes_count')\n",
    "df_en_test = load_from_database(db='review_en_sc_test', table='review_en_sc_test',\n",
    "                                columns='user_id, wine_id, note, rating, likes_count')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = load_from_database(db='review_en_sentiment', table='review_en_sentiment',\n",
    "                        columns='user_id, wine_id, note, rating, likes_count')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6096\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "user = 56640092\n",
    "rated_train = df_en_train[df_en_train['user_id'] == user]['wine_id']\n",
    "rated_test = df_en_test[df_en_test['user_id'] == user]['wine_id']\n",
    "df_temp = df_en_train[df_en_train['wine_id'].isin(rated_train)]\n",
    "print(len(df_temp))\n",
    "print(len(df_temp[df_temp['user_id'].isin(\n",
    "    df_en_test[df_en_test['wine_id'].isin(rated_test)]['user_id']\n",
    ")]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.176 \n",
      " 0.41952353926806063\n",
      "0:00:01.019047\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "        df_train: pd.DataFrame = args[0]\n",
    "        df_test: pd.DataFrame = args[1]\n",
    "        input_user_list = args[2]\n",
    "        n_user: int = args[3]\n",
    "        type_name: str = args[4]\n",
    "        is_evaluation: bool = args[5]\n",
    "        truncate: bool = args[6]\n",
    "    \"\"\"\n",
    "start = datetime.datetime.now()\n",
    "predictions = recommender_system.evaluate_recommender(\n",
    "    [\n",
    "        df_en_train,\n",
    "        df_en_test,\n",
    "        [56640092],\n",
    "        5,\n",
    "        'nlp',\n",
    "        True,\n",
    "        False,\n",
    "        '../models/zero-shot'\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    str(mean_squared_error(y_pred=predictions['prediction'], y_true=predictions['rating'])), '\\n',\n",
    "    str(mean_squared_error(y_pred=predictions['prediction'], y_true=predictions['rating'], squared=False))\n",
    ")\n",
    "print(datetime.datetime.now() - start)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate NLP Recommender"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/wzymnpfd4rjdkg4k8khhk6dc0000gn/T/ipykernel_2160/248824822.py:59: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  df.to_sql(name='rs_evaluation', con=con_rs_evaluation, if_exists='append')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457044\n",
      "11:35:50.588686\n"
     ]
    }
   ],
   "source": [
    "# Credits split method: https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return list(a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "\n",
    "def start_nlp():\n",
    "    df_intersection = list(set(df_en_test['user_id']) & set(df_en_train['user_id']))\n",
    "    df_test = df_en_test[df_en_test['user_id'].isin(df_intersection)]\n",
    "    df_train = df_en_train[df_en_train['user_id'].isin(df_intersection)]\n",
    "    input_user_ids = df_intersection\n",
    "    core_count = 4\n",
    "    input_user_id_frames = split(input_user_ids, core_count)\n",
    "    type = 'nlp'\n",
    "    model = 'simcse_en_sc'\n",
    "    model_path = '../models/' + model\n",
    "    \"\"\"\n",
    "        df_train: pd.DataFrame = args[0]\n",
    "        df_test: pd.DataFrame = args[1]\n",
    "        input_user_list = args[2]\n",
    "        n_user: int = args[3]\n",
    "        type_name: str = args[4]\n",
    "        is_evaluation: bool = args[5]\n",
    "        truncate: bool = args[6]\n",
    "    \"\"\"\n",
    "    data: list = list()\n",
    "    for i in range(core_count):\n",
    "        data.append([\n",
    "            df_train,\n",
    "            df_test,\n",
    "            input_user_id_frames[i],\n",
    "            5,\n",
    "            type,\n",
    "            True,\n",
    "            False,\n",
    "            model_path\n",
    "        ])\n",
    "    multi_pool = Pool(processes=core_count)\n",
    "    start = datetime.datetime.now()\n",
    "    predictions = multi_pool.map(recommender_system.evaluate_recommender, data)\n",
    "    df_results = pd.concat(predictions)\n",
    "    multi_pool.close()\n",
    "    multi_pool.join()\n",
    "    duration = datetime.datetime.now() - start\n",
    "\n",
    "    mse: float = mean_squared_error(y_pred=df_results['prediction'], y_true=df_results['rating'])\n",
    "    rmse: float = mean_squared_error(y_pred=df_results['prediction'], y_true=df_results['rating'], squared=False)\n",
    "    con_rs_evaluation = sqlite3.connect('../database/rs_evaluation.db')\n",
    "    if type == 'nlp':\n",
    "        type = str(type + ' (' + model + ')')\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'date': [datetime.datetime.now()],\n",
    "            'duration (in ns)': [duration],\n",
    "            'mse': [mse],\n",
    "            'rmse': [rmse],\n",
    "            'type': [type],\n",
    "        }\n",
    "    )\n",
    "    df.to_sql(name='rs_evaluation', con=con_rs_evaluation, if_exists='append')\n",
    "    con_predictions = sqlite3.connect('../database/predictions.db')\n",
    "    df_results.to_sql(name='nlp_simcse_en_sc', con=con_predictions, if_exists='replace')\n",
    "    con_predictions.close()\n",
    "    con_rs_evaluation.close()\n",
    "    print(len(df_results))\n",
    "    print(duration)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_nlp()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate Reference Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:07.966758\n"
     ]
    }
   ],
   "source": [
    "# Credits split method: https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return list(a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "\n",
    "\n",
    "def start_numeric():\n",
    "    df_intersection = list(set(df_en_test['user_id']) & set(df_en_train['user_id']))\n",
    "    df_test = df_en_test[df_en_test['user_id'].isin(df_intersection)]\n",
    "    df_train = df_en_train[df_en_train['user_id'].isin(df_intersection)]\n",
    "    input_user_ids = df_intersection\n",
    "    core_count = 3\n",
    "    input_user_id_frames = split(input_user_ids, core_count)\n",
    "\n",
    "    # del df_en_train, df_en_test\n",
    "\n",
    "    type_var = 'numeric'\n",
    "\n",
    "    df_results = pd.DataFrame()\n",
    "    \"\"\"\n",
    "        df_train: pd.DataFrame = args[0]\n",
    "        df_test: pd.DataFrame = args[1]\n",
    "        n_predictions: int = args[2]\n",
    "        input_user_list = args[3]\n",
    "    \"\"\"\n",
    "    start = datetime.datetime.now()\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = [\n",
    "            executor.submit(collaborative_filtering_numeric.evaluate_recommender, [\n",
    "                df_test,  # 0\n",
    "                df_train,  # 1\n",
    "                20,  # 2\n",
    "                input_user_id_frames[i],  # 3\n",
    "            ]) for i in range(core_count)]\n",
    "\n",
    "        for result in concurrent.futures.as_completed(results):\n",
    "            df_results = pd.concat([df_results, result.result()])\n",
    "\n",
    "        mse: float = mean_squared_error(y_pred=df_results['prediction'], y_true=df_results['rating'])\n",
    "        rmse: float = mean_squared_error(y_pred=df_results['prediction'], y_true=df_results['rating'], squared=False)\n",
    "        con_rs_evaluation = sqlite3.connect('../database/rs_evaluation.db')\n",
    "        duration = datetime.datetime.now() - start\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                'date': [datetime.datetime.now()],\n",
    "                'duration (in ns)': [duration],\n",
    "                'mse': [mse],\n",
    "                'rmse': [rmse],\n",
    "                'type': [type_var],\n",
    "            }\n",
    "        )\n",
    "        df.to_sql(name='rs_evaluation', con=con_rs_evaluation, if_exists='append')\n",
    "        print(duration)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_numeric()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
